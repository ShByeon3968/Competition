import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import timm
import os
from tqdm import tqdm
from torchmetrics import MetricCollection
from torchmetrics.classification import MulticlassAccuracy
import glob
from torch.optim.lr_scheduler import CosineAnnealingLR
from utils import get_topk_confusing_pairs

# í•˜ì´í¼íŒŒë¼ë¯¸í„°
NUM_CLASSES = 7
BATCH_SIZE = 32
EPOCHS = 30
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
RESUME = True  # ì´ì–´ì„œ í•™ìŠµí•˜ë ¤ë©´ True

# í´ë˜ìŠ¤ ëª©ë¡ (train_dataset.classes ìˆœì„œ)
class_names = ['Andesite', 'Basalt', 'Etc', 'Gneiss', 'Granite', 'Mud_Sandstone', 'Weathered_Rock']
NUM_CLASSES = len(class_names)

# ë°ì´í„° ì „ì²˜ë¦¬ (ImageNet ê¸°ì¤€)
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(p=0.3),                      # ìˆ˜ì§ ë°˜ì „
    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),                 # ìƒ‰ìƒ ë³€í™”
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])
transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# í‰ê°€ ì§€í‘œ
metrics = MetricCollection({
    'acc': MulticlassAccuracy(num_classes=NUM_CLASSES, average='macro')
}).to(DEVICE)

# ë°ì´í„° ë¡œë”©
train_dataset = datasets.ImageFolder(root='./data/train', transform=transform_train)
val_dataset = datasets.ImageFolder(root='./data/val', transform=transform_val)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

# âœ… EfficientNet ëª¨ë¸ ì •ì˜
model = timm.create_model('tf_efficientnet_b4_ns', pretrained=True, num_classes=NUM_CLASSES)
model.to(DEVICE)

# ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¥´ëŸ¬
criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
optimizer = optim.AdamW(model.parameters(), lr=1e-4)
scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)

# ì›¨ì´íŠ¸ ì´ˆê¸°í™”
default_weights = torch.ones(NUM_CLASSES, dtype=torch.float)
confused_boost = 2.0
topk_confused = 5
top_confused = []

# ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
start_epoch = 0
if RESUME:
    checkpoint_files = sorted(glob.glob('./checkpoints/efficientnet_epoch_*.pt'))
    if checkpoint_files:
        latest_ckpt = checkpoint_files[-1]
        checkpoint = torch.load(latest_ckpt, map_location=DEVICE)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint['epoch']
        print(f"Resumed from checkpoint: {latest_ckpt} (Epoch {start_epoch})")
    else:
        print("âš ï¸ No checkpoint found. Starting from scratch.")

# ---------------------í•™ìŠµ ë£¨í”„---------------------
for epoch in range(start_epoch, EPOCHS):
    if epoch > 0:
        weight_vector = default_weights.clone()
        for (c1, c2), _ in top_confused:
            idx1, idx2 = class_names.index(c1), class_names.index(c2)
            weight_vector[idx1] *= confused_boost
            weight_vector[idx2] *= confused_boost
        criterion = nn.CrossEntropyLoss(weight=weight_vector.to(DEVICE), label_smoothing=0.1)
        print(f"ğŸ“Š Updated class weights based on confusion: {weight_vector}")
    else:
        # ì²« epochì€ default weight ì‚¬ìš©
        criterion = nn.CrossEntropyLoss(weight=default_weights.to(DEVICE), label_smoothing=0.1)

    model.train()
    total_loss, correct = 0, 0

    for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1} [Train]"):
        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        correct += (outputs.argmax(1) == labels).sum().item()

    avg_loss = total_loss / len(train_loader)
    train_acc = correct / len(train_loader.dataset)
    print(f"[Train] Epoch {epoch+1}, Loss: {avg_loss:.4f}, Acc: {train_acc:.4f}")

    # âœ… scheduler step í˜¸ì¶œ
    scheduler.step()
    # ê²€ì¦
    model.eval()
    y_true, y_pred = [], []
    metrics.reset()
    with torch.no_grad():
        for imgs, labels in tqdm(val_loader, desc=f"Epoch {epoch+1} [Val]"):
            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
            outputs = model(imgs)
            preds = outputs.argmax(1)
            metrics.update(preds, labels)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())

    result = metrics.compute()
    print(f"[Val Accuracy] Macro: {result['acc']:.4f}")

    # í˜¼ë™ í´ë˜ìŠ¤ í˜ì–´ íƒì§€
    top_confused = get_topk_confusing_pairs(y_true, y_pred, class_names, topk=topk_confused)
    print(f"âš ï¸ Top-{topk_confused} Confusing Class Pairs (Epoch {epoch+1}):")
    for (c1, c2), freq in top_confused:
        print(f"   - {c1} â†” {c2}: {freq}ë²ˆ í˜¼ë™")

    # ëª¨ë¸ ì €ì¥
    save_path = f"./checkpoints/efficientnet_epoch_{epoch+1}.pt"
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    torch.save({
        'epoch': epoch + 1,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'val_accuracy': result['acc'].item()
    }, save_path)
    print(f"âœ… Model saved to {save_path}")
